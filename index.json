[{"content":"","date":"1 September 2024","externalUrl":null,"permalink":"/tags/ansible/","section":"Tags","summary":"","title":"Ansible","type":"tags"},{"content":"","date":"1 September 2024","externalUrl":null,"permalink":"/blog/","section":"Blogs","summary":"","title":"Blogs","type":"blog"},{"content":"","date":"2024-09-01","externalUrl":null,"permalink":"/zh-cn/tags/daily/","section":"Tags","summary":"","title":"Daily","type":"tags"},{"content":"","date":"1 September 2024","externalUrl":null,"permalink":"/blog/euro-tourist/euro-tourist/","section":"Blogs","summary":"","title":"Euro travel experience and recommendation","type":"blog"},{"content":"","date":"1 September 2024","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"1 September 2024","externalUrl":null,"permalink":"/","section":"Wei's Home","summary":"","title":"Wei's Home","type":"page"},{"content":"Handling errors during environment configuration with Ansible is crucial. While ignore_errors and fails_when keywords exist, they only apply to specific tasks, not to roles or entire playbooks.\nProblem Description # ignore_errors=true is ineffective in Ansible roles, only working within sessions. This requires repeatedly adding this option in test and subsequent tasks to ensure the next test runs even if the previous one fails. How can we avoid overusing ignore_errors and skip tests if pre-tasks fail?\nSolution # Refactor test cases using block, rescue, always, and clear_host_errors.\nExample:\n- block: - name: Pre tasks command: /bin/false - name: Test tasks command: /bin/false register: result rescue: - name: Record error ansible.builtin.debug: var: result always: - name: Post tasks command: echo \u0026#34;post tasks\u0026#34; - name: Clear host errors meta: clear_host_errors Detailed Explanation # Using ignore_errors:\nIn Ansible, if a task fails, Ansible will stop executing tasks on that host by default. However, you can use ignore_errors to ignore errors and continue execution. For example:\n- name: Attempt to Execute a Command command: /some/nonexistent/command ignore_errors: true # This task will fail, but the playbook will continue. Using block, rescue, and always By breaking down each role\u0026rsquo;s tasks into multiple parts and using the block, rescue, and always keywords, more granular error handling can be achieved. As seen in the example above, if the pre task fails, the test task will not be executed because they are in the same block. The failure of an Ansible task will trigger the execution of the rescue block, where we can log errors. In the example, debug is used, but you can also write to a verdict/any file so that we can judge the overall test results in the end. Regardless of the execution status of the tasks in the block, the post task will always be executed. In the post task, you can add tasks such as collecting logs. Even if it fails, the tasks in always will still be executed. Finally, by using clear_host_error, the error is removed, so Ansible will not stop executing tasks on that host, and the next test block will still be executed.\nThis structure can build multiple tests in a playbook without affecting each other, which can reduce the number of VMs that need to be started at the same time to a certain extent.\nReferences # Ansible Error Handling ","date":"14 August 2024","externalUrl":null,"permalink":"/blog/ansible-ignore-errors/ansible-ignore-errors/","section":"Blogs","summary":"Handling errors during environment configuration with Ansible is crucial. While ignore_errors and fails_when keywords exist, they only apply to specific tasks, not to roles or entire playbooks.\nProblem Description # ignore_errors=true is ineffective in Ansible roles, only working within sessions.","title":"Ansible complex set up error handling","type":"blog"},{"content":" When we have little data need to pass from helm chart to service, it quit easy to use the container.env part in the deployment.yaml. So that we could just os.getEnv() in the code, we got the value we want.\nBut what if we have a lot of values to pass, it is a mess to add them all in the helm chart. Then, we could use config map here. Personally, I prefer to use the JSON format, because it is easy to un-marshal to struct, and we can get easy access to all the values.\nHere are the exact steps to pass data through config map:\nSet up a config map with json format data.\napiVersion: \u0026#34;v1\u0026#34; kind: \u0026#34;ConfigMap\u0026#34; metadata: name: json-configmap data: config.json: | { \u0026#34;key1\u0026#34;: \u0026#34;value1\u0026#34;, \u0026#34;key2\u0026#34;: \u0026#34;value2\u0026#34; } Create a volume in the pod and mount it to the container we want.\napiVersion: \u0026#34;apps/v1\u0026#34; kind: \u0026#34;Deployment\u0026#34; metadata: name: \u0026#34;test-service\u0026#34; spec: - template: metadata: volumes: - name: \u0026#34;json-config-volume\u0026#34; configMap: // make sure the name equals to the name in configmap metadata.name name: \u0026#34;json-configmap\u0026#34; containers: - name: \u0026#34;container-first\u0026#34; volumeMounts: - name: \u0026#34;config-volume\u0026#34; mountPath: \u0026#34;/etc/config\u0026#34; // not necessary, you can hardcoded in the code base, put it here just make sure // if anyday we changed the mountpath, make sure change the env as well. env: - name: \u0026#34;CONFIG_FILE\u0026#34; value: \u0026#34;/etc/config/config.json\u0026#34; In the code base, we can through os.getEnv() get easy access to the JSON file and do the un-marshal to it.\n// Based on the json format type JsonConfig struct{ key1 string key2 string } func getJsonConfig() error{ filePath, ok := os.LookupEnv(\u0026#34;CONFIG_FILE\u0026#34;) if !ok { return errors.New(\u0026#34;failed to get file path\u0026#34;) } config, err := os.Open(filePath) if err != nil { return errors.Wrap(err, \u0026#34;failed to open file\u0026#34;) } defer config.Close() byteValue, err := io.ReadAll(config) if err != nil { return errors.Wrap(err, \u0026#34;failed to read file\u0026#34;) } jsonConfig := \u0026amp;JsonConfig{} if err = json.Unmarshal(byteValue, jsonConfig); err != nil { return errors.Wrap(err, \u0026#34;failed to unmarshal file\u0026#34;) } return nil } ","date":"25 May 2023","externalUrl":null,"permalink":"/blog/pass-data-in-json/pass-data-in-json/","section":"Blogs","summary":"When we have little data need to pass from helm chart to service, it quit easy to use the container.env part in the deployment.yaml. So that we could just os.","title":"How to pass data in JSON format in config map to the microservice","type":"blog"},{"content":"","date":"25 May 2023","externalUrl":null,"permalink":"/tags/kubernetes/","section":"Tags","summary":"","title":"Kubernetes","type":"tags"},{"content":" Readiness and Liveness probe Configure Liveness, Readiness and Startup Probes | Kubernetes The kubelet uses liveness probes to know when to restart a container. For example, liveness probes could catch a deadlock, where an application is running, but unable to make progress. Restarting a container in such a state can help to make the application more available despite bugs. The kubelet uses readiness probes to know when a container is ready to start accepting traffic. A Pod is considered ready when all of its containers are ready. One use of this signal is to control which Pods are used as backends for Services. When a Pod is not ready, it is removed from Service load balancers. The readiness check will continuously run in the pod lifecycle. As long as Liveness Probe passed, the pod status changed to running. If you want to connect to a pod when it is ready for traffic, it is better to check the ready keywords.\nPod lifecycle Pod Lifecycle | Kubernetes Value Description Pending The Pod has been accepted by the Kubernetes cluster, but one or more of the containers has not been set up and made ready to run. This includes time a Pod spends waiting to be scheduled as well as the time spent downloading container images over the network. Running The Pod has been bound to a node, and all of the containers have been created. At least one container is still running, or is in the process of starting or restarting. Succeeded All containers in the Pod have terminated in success, and will not be restarted. Failed All containers in the Pod have terminated, and at least one container has terminated in failure. That is, the container either exited with non-zero status or was terminated by the system. Unknown For some reason the state of the Pod could not be obtained. This phase typically occurs due to an error in communicating with the node where the Pod should be running. When a Pod is being deleted, it is shown as Terminating by some kubectl commands. This Terminating status is not one of the Pod phases. A Pod is granted a term to terminate gracefully, which defaults to 30 seconds. You can use the flag --force to terminate a Pod by force.\n","date":"25 January 2023","externalUrl":null,"permalink":"/blog/kubernetes-pods-lifecycle/","section":"Blogs","summary":"Readiness and Liveness probe Configure Liveness, Readiness and Startup Probes | Kubernetes The kubelet uses liveness probes to know when to restart a container. For example, liveness probes could catch a deadlock, where an application is running, but unable to make progress.","title":"Kubernetes probes and pod lifecycle","type":"blog"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]