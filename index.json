[{"content":" When we have little data need to pass from helm chart to service, it quit easy to use the container.env part in the deployment.yaml. So that we could just os.getEnv() in the code, we got the value we want. But what if we have a lot of values to pass, it is a mess to add them all in the helm chart. Then, we could use config map here. Personally, I prefer to use the JSON format, because it is easy to un-marshal to struct, and we can get easy access to all the values. Here are the exact steps to pass data through config map: Set up a config map with json format data apiVersion: \u0026#34;v1\u0026#34; kind: \u0026#34;ConfigMap\u0026#34; metadata: name: json-configmap data: config.json: | { \u0026#34;key1\u0026#34;: \u0026#34;value1\u0026#34;, \u0026#34;key2\u0026#34;: \u0026#34;value2\u0026#34; } Create a volume in the pod and mount it to the container we want. apiVersion: \u0026#34;apps/v1\u0026#34; kind: \u0026#34;Deployment\u0026#34; metadata: name: \u0026#34;test-service\u0026#34; spec: template: metadata: volumes: - name: \u0026#34;json-config-volume\u0026#34; configMap: // make sure the name equals to the name in configmap metadata.name name: \u0026#34;json-configmap\u0026#34; containers: - name: \u0026#34;container-first\u0026#34; volumeMounts: - name: \u0026#34;config-volume\u0026#34; mountPath: \u0026#34;/etc/config\u0026#34; // not necessary, you can hardcoded in the code base, put it here just make sure // if anyday we changed the mountpath, make sure change the env as well. env: - name: \u0026#34;CONFIG_FILE\u0026#34; value: \u0026#34;/etc/config/config.json\u0026#34; In the code base, we can through os.getEnv() get easy access to the JSON file and do the un-marshal to it. // Based on the json format type JsonConfig struct{ key1 string key2 string } func getJsonConfig() error{ filePath, ok := os.LookupEnv(\u0026#34;CONFIG_FILE\u0026#34;) if !ok { return errors.New(\u0026#34;failed to get file path\u0026#34;) } config, err := os.Open(filePath) if err != nil { return errors.Wrap(err, \u0026#34;failed to open file\u0026#34;) } defer config.Close() byteValue, err := io.ReadAll(config) if err != nil { return errors.Wrap(err, \u0026#34;failed to read file\u0026#34;) } jsonConfig := \u0026amp;JsonConfig{} if err = json.Unmarshal(byteValue, jsonConfig); err != nil { return errors.Wrap(err, \u0026#34;failed to unmarshal file\u0026#34;) } return nil } ","permalink":"http://weiguo98.github.io/posts/pass-data-in-json/","summary":"When we have little data need to pass from helm chart to service, it quit easy to use the container.env part in the deployment.yaml. So that we could just os.getEnv() in the code, we got the value we want. But what if we have a lot of values to pass, it is a mess to add them all in the helm chart. Then, we could use config map here. Personally, I prefer to use the JSON format, because it is easy to un-marshal to struct, and we can get easy access to all the values.","title":"How to pass data in JSON format in config map to the microservice"},{"content":" Readiness and Liveness probe Configure Liveness, Readiness and Startup Probes | Kubernetes The kubelet uses liveness probes to know when to restart a container. For example, liveness probes could catch a deadlock, where an application is running, but unable to make progress. Restarting a container in such a state can help to make the application more available despite bugs. The kubelet uses readiness probes to know when a container is ready to start accepting traffic. A Pod is considered ready when all of its containers are ready. One use of this signal is to control which Pods are used as backends for Services. When a Pod is not ready, it is removed from Service load balancers. The readiness check will continuously run in the pod lifecycle. As long as Liveness Probe passed, the pod status changed to running. If you want to connect to a pod when it is ready for traffic, it is better to check the ready keywords.\nPod lifecycle Pod Lifecycle | Kubernetes Value Description Pending The Pod has been accepted by the Kubernetes cluster, but one or more of the containers has not been set up and made ready to run. This includes time a Pod spends waiting to be scheduled as well as the time spent downloading container images over the network. Running The Pod has been bound to a node, and all of the containers have been created. At least one container is still running, or is in the process of starting or restarting. Succeeded All containers in the Pod have terminated in success, and will not be restarted. Failed All containers in the Pod have terminated, and at least one container has terminated in failure. That is, the container either exited with non-zero status or was terminated by the system. Unknown For some reason the state of the Pod could not be obtained. This phase typically occurs due to an error in communicating with the node where the Pod should be running. When a Pod is being deleted, it is shown as Terminating by some kubectl commands. This Terminating status is not one of the Pod phases. A Pod is granted a term to terminate gracefully, which defaults to 30 seconds. You can use the flag --force to terminate a Pod by force. ","permalink":"http://weiguo98.github.io/posts/my-first-post/","summary":"Readiness and Liveness probe Configure Liveness, Readiness and Startup Probes | Kubernetes The kubelet uses liveness probes to know when to restart a container. For example, liveness probes could catch a deadlock, where an application is running, but unable to make progress. Restarting a container in such a state can help to make the application more available despite bugs. The kubelet uses readiness probes to know when a container is ready to start accepting traffic.","title":"Kubernetes probes and pod lifecycle"}]