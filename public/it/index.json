






[{"content":"","date":"14 agosto 2024","externalUrl":null,"permalink":"/tags/ansible/","section":"Tags","summary":"","title":"Ansible","type":"tags"},{"content":"Handling errors during environment configuration with Ansible is crucial. While ignore_errors and fails_when keywords exist, they only apply to specific tasks, not to roles or entire playbooks.\nProblem Description # ignore_errors=true is ineffective in Ansible roles, only working within sessions. This requires repeatedly adding this option in test and subsequent tasks to ensure the next test runs even if the previous one fails. How can we avoid overusing ignore_errors and skip tests if pre-tasks fail?\nSolution # Refactor test cases using block, rescue, always, and clear_host_errors.\nExample:\n- block: - name: Pre tasks command: /bin/false - name: Test tasks command: /bin/false register: result rescue: - name: Record error ansible.builtin.debug: var: result always: - name: Post tasks command: echo \u0026#34;post tasks\u0026#34; - name: Clear host errors meta: clear_host_errors Detailed Explanation # Using ignore_errors:\nIn Ansible, if a task fails, Ansible will stop executing tasks on that host by default. However, you can use ignore_errors to ignore errors and continue execution. For example:\n- name: Attempt to Execute a Command command: /some/nonexistent/command ignore_errors: true # This task will fail, but the playbook will continue. Using block, rescue, and always By breaking down each role\u0026rsquo;s tasks into multiple parts and using the block, rescue, and always keywords, more granular error handling can be achieved. As seen in the example above, if the pre task fails, the test task will not be executed because they are in the same block. The failure of an Ansible task will trigger the execution of the rescue block, where we can log errors. In the example, debug is used, but you can also write to a verdict/any file so that we can judge the overall test results in the end. Regardless of the execution status of the tasks in the block, the post task will always be executed. In the post task, you can add tasks such as collecting logs. Even if it fails, the tasks in always will still be executed. Finally, by using clear_host_error, the error is removed, so Ansible will not stop executing tasks on that host, and the next test block will still be executed.\nThis structure can build multiple tests in a playbook without affecting each other, which can reduce the number of VMs that need to be started at the same time to a certain extent.\nReferences # Ansible Error Handling ","date":"14 agosto 2024","externalUrl":null,"permalink":"/docs/ansible-ignore-errors/ansible-ignore-errors/","section":"Docs","summary":"Handling errors during environment configuration with Ansible is crucial. While ignore_errors and fails_when keywords exist, they only apply to specific tasks, not to roles or entire playbooks.\nProblem Description # ignore_errors=true is ineffective in Ansible roles, only working within sessions.","title":"Ansible complex set up error handling","type":"docs"},{"content":"","date":"14 agosto 2024","externalUrl":null,"permalink":"/docs/","section":"Docs","summary":"","title":"Docs","type":"docs"},{"content":" When we have little data need to pass from helm chart to service, it quit easy to use the container.env part in the deployment.yaml. So that we could just os.getEnv() in the code, we got the value we want. But what if we have a lot of values to pass, it is a mess to add them all in the helm chart. Then, we could use config map here. Personally, I prefer to use the JSON format, because it is easy to un-marshal to struct, and we can get easy access to all the values. Here are the exact steps to pass data through config map: Set up a config map with json format data apiVersion: \u0026#34;v1\u0026#34; kind: \u0026#34;ConfigMap\u0026#34; metadata: name: json-configmap data: config.json: | { \u0026#34;key1\u0026#34;: \u0026#34;value1\u0026#34;, \u0026#34;key2\u0026#34;: \u0026#34;value2\u0026#34; } Create a volume in the pod and mount it to the container we want. apiVersion: \u0026#34;apps/v1\u0026#34; kind: \u0026#34;Deployment\u0026#34; metadata: name: \u0026#34;test-service\u0026#34; spec: template: metadata: volumes: - name: \u0026#34;json-config-volume\u0026#34; configMap: // make sure the name equals to the name in configmap metadata.name name: \u0026#34;json-configmap\u0026#34; containers: - name: \u0026#34;container-first\u0026#34; volumeMounts: - name: \u0026#34;config-volume\u0026#34; mountPath: \u0026#34;/etc/config\u0026#34; // not necessary, you can hardcoded in the code base, put it here just make sure // if anyday we changed the mountpath, make sure change the env as well. env: - name: \u0026#34;CONFIG_FILE\u0026#34; value: \u0026#34;/etc/config/config.json\u0026#34; In the code base, we can through os.getEnv() get easy access to the JSON file and do the un-marshal to it. // Based on the json format type JsonConfig struct{ key1 string key2 string } func getJsonConfig() error{ filePath, ok := os.LookupEnv(\u0026#34;CONFIG_FILE\u0026#34;) if !ok { return errors.New(\u0026#34;failed to get file path\u0026#34;) } config, err := os.Open(filePath) if err != nil { return errors.Wrap(err, \u0026#34;failed to open file\u0026#34;) } defer config.Close() byteValue, err := io.ReadAll(config) if err != nil { return errors.Wrap(err, \u0026#34;failed to read file\u0026#34;) } jsonConfig := \u0026amp;JsonConfig{} if err = json.Unmarshal(byteValue, jsonConfig); err != nil { return errors.Wrap(err, \u0026#34;failed to unmarshal file\u0026#34;) } return nil } ","date":"25 maggio 2023","externalUrl":null,"permalink":"/docs/pass-data-in-json/pass-data-in-json/","section":"Docs","summary":"When we have little data need to pass from helm chart to service, it quit easy to use the container.env part in the deployment.yaml. So that we could just os.","title":"How to pass data in JSON format in config map to the microservice","type":"docs"},{"content":"","date":"25 maggio 2023","externalUrl":null,"permalink":"/tags/kubernetes/","section":"Tags","summary":"","title":"Kubernetes","type":"tags"},{"content":"Before landed in Sweden:\npassport and work permit check the work permit progress. immigration agency, you can also get more information about what kind of documenation is needed, and read some requirements of it. pack the luggage There are some normal stufff that for travelling, I think there is no need to repeat. But here are something like I think it is important to bring if you are first come to Sweden. raincoat/防水外套: There is always some rain during winter, autumn and spring. And since Gothenburg is near the sea, it is also super windy. As a result, most of the time, it is not a good idea to use the umbrella. I would recommand to bring the anti-water coat, it would be much easier and almost every swedes have one. some hometown kitchenware and food: Sweden food is not very fancy and interesting. If you are from a country full of deleicious food, I recommend you to bring some special pot/species that can used for cooking. For sure, you gonna miss that. Adpater. If you are not from Euorpe, makee sure to bring appropriate adapters. But if you forget, it is fine you can always buy it from clas oshon. Frist landed in Sweden:\nAccomandation: Our company will find the suitable recommandation for you, so you can just go there and have a rest. Life use and food The supermarket you can search is here: coop, ica, willys, lidl 电器店： 杂货店：clas oson， dollar store， 家具：ikea, jysk, hm\u0026amp;home supermall: nordstan personal number and id card tax agency: wait from 2 week to several months bank card and bank id nordea seb swedenbank phone and phone number: company provided transportation: vatsirfic, buy tikcet in pressbyran. Settled down in Sweden:\nAccommandation: rent: homeq, boplast/blocket buy: hemtex Culture: Fika: Teamwork, collobration Call by name food: kottbullar, herrings(julborad) midsummer outdoor activities Language: SFI(free) folks university Trip in Gothenburg\nIslands: hono Seaside Event web: Museum ","date":"1 marzo 2023","externalUrl":null,"permalink":"/docs/move-to-sweden/","section":"Docs","summary":"Before landed in Sweden: passport and work permit check the work permit progress. immigration agency, you can also get more information about what kind of documenation is needed, and read","title":"What to prepare when got a job in Sweden","type":"docs"},{"content":" Readiness and Liveness probe Configure Liveness, Readiness and Startup Probes | Kubernetes The kubelet uses liveness probes to know when to restart a container. For example, liveness probes could catch a deadlock, where an application is running, but unable to make progress. Restarting a container in such a state can help to make the application more available despite bugs. The kubelet uses readiness probes to know when a container is ready to start accepting traffic. A Pod is considered ready when all of its containers are ready. One use of this signal is to control which Pods are used as backends for Services. When a Pod is not ready, it is removed from Service load balancers. The readiness check will continuously run in the pod lifecycle. As long as Liveness Probe passed, the pod status changed to running. If you want to connect to a pod when it is ready for traffic, it is better to check the ready keywords.\nPod lifecycle Pod Lifecycle | Kubernetes Value Description Pending The Pod has been accepted by the Kubernetes cluster, but one or more of the containers has not been set up and made ready to run. This includes time a Pod spends waiting to be scheduled as well as the time spent downloading container images over the network. Running The Pod has been bound to a node, and all of the containers have been created. At least one container is still running, or is in the process of starting or restarting. Succeeded All containers in the Pod have terminated in success, and will not be restarted. Failed All containers in the Pod have terminated, and at least one container has terminated in failure. That is, the container either exited with non-zero status or was terminated by the system. Unknown For some reason the state of the Pod could not be obtained. This phase typically occurs due to an error in communicating with the node where the Pod should be running. When a Pod is being deleted, it is shown as Terminating by some kubectl commands. This Terminating status is not one of the Pod phases. A Pod is granted a term to terminate gracefully, which defaults to 30 seconds. You can use the flag --force to terminate a Pod by force. ","date":"25 gennaio 2023","externalUrl":null,"permalink":"/docs/my-first-post/","section":"Docs","summary":"Readiness and Liveness probe Configure Liveness, Readiness and Startup Probes | Kubernetes The kubelet uses liveness probes to know when to restart a container. For example, liveness probes could catch a deadlock, where an application is running, but unable to make progress.","title":"Kubernetes probes and pod lifecycle","type":"docs"},{"content":"","externalUrl":null,"permalink":"/it/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/it/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/it/","section":"My New Hugo Site","summary":"","title":"My New Hugo Site","type":"page"},{"content":"","externalUrl":null,"permalink":"/it/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"","externalUrl":null,"permalink":"/it/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"}]